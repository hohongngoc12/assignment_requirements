import json
import requests
from bs4 import BeautifulSoup
import pandas as pd

def GetSoup(url):
    response = requests.get(url)
    html_content = response.content
    soup = BeautifulSoup(html_content, 'html.parser')
    return soup

link = []
text = []
title = []

for i in range(50):  # Lặp qua 50 trang
    url = f"https://vnexpress.net/phap-luat-p{i}"
    soup = GetSoup(url)
    descriptions = soup.find_all('p', class_='description')
    
    for desc in descriptions:
        try:
            link.append(desc.a['href'])
            text.append(desc.a.text.strip())
            title.append(desc.a['title'])
        except Exception as e:
            print(f"Error: {e}")

# Tạo DataFrame từ dữ liệu
data = {
    'Title': title,
    'Text': text,
    'Link': link
}

df = pd.DataFrame(data)

# Chuyển DataFrame thành một danh sách các dictionaries
data_json = df.to_dict(orient='records')

# Ghi dữ liệu vào tệp JSON
with open('vnexpress_data.json', 'w', encoding='utf-8') as f:
    json.dump(data_json, f, ensure_ascii=False)

print("Data saved to 'vnexpress_data.json' file.")
